{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9dde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "BASE_DIR = Path(r'U:\\Abt02\\Ref23\\Daten\\LQ-Modellierung\\06_Modellierung\\04_WINMiskam\\02_Meteorologie')\n",
    "YEAR = 2009\n",
    "IN_PATH = BASE_DIR / 'data' / 'processed' / f'merged_wind_cloud_{YEAR}_day_night.csv'\n",
    "OUT_PATH = BASE_DIR / 'data' / 'processed' / f'merged_wind_cloud_{YEAR}_day_night_ausbreitung.csv'\n",
    "\n",
    "TZ_NAME = 'UTC'\n",
    "try:\n",
    "    pd.Timestamp('2000-01-01', tz=TZ_NAME)\n",
    "except Exception:\n",
    "    TZ_NAME = 'UTC'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2317db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(IN_PATH)\n",
    "# Use the provided local timestamps from the merged dataset\n",
    "df['timestamp_local'] = pd.to_datetime(df['timestamp_local'], errors='coerce')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "\n",
    "# Add an extra local hour (2010-01-01 00:00) so the series still covers full 2009\n",
    "last_row = df.iloc[-1].copy()\n",
    "extra_row = last_row.copy()\n",
    "ts_step = pd.Timedelta(hours=1)\n",
    "ts_day = pd.Timedelta(days=1)\n",
    "\n",
    "next_ts = pd.to_datetime(last_row['timestamp_local'], errors='coerce') + ts_step\n",
    "local_last = pd.to_datetime(last_row['timestamp_local'], errors='coerce')\n",
    "if getattr(local_last, 'tzinfo', None) is None:\n",
    "    local_last = local_last.tz_localize(TZ_NAME, ambiguous='NaT', nonexistent='shift_forward')\n",
    "\n",
    "extra_row['timestamp'] = next_ts.strftime('%Y-%m-%d %H:%M:%S')\n",
    "extra_row['timestamp_local'] = (local_last + ts_step).isoformat()\n",
    "sa_last = pd.to_datetime(last_row['SA'], errors='coerce')\n",
    "su_last = pd.to_datetime(last_row['SU'], errors='coerce')\n",
    "extra_row['SA'] = (sa_last + ts_day).isoformat() if pd.notna(sa_last) else None\n",
    "extra_row['SU'] = (su_last + ts_day).isoformat() if pd.notna(su_last) else None\n",
    "extra_row['MESS_DATUM'] = int(pd.to_datetime(next_ts, errors='coerce').strftime('%Y%m%d%H'))\n",
    "df = pd.concat([df, pd.DataFrame([extra_row])], ignore_index=True)\n",
    "\n",
    "def _ensure_tz(series, tz_name):\n",
    "    \"\"\"\n",
    "    Coerce any input to tz-aware datetimes in the given zone.\n",
    "    Handles Series or array-like and tolerates invalids (-> NaT).\n",
    "    \"\"\"\n",
    "    ts = pd.to_datetime(series, errors='coerce')\n",
    "    if isinstance(ts, pd.Series) and not is_datetime64_any_dtype(ts):\n",
    "        # Mixed timezone offsets become object dtype; parse with utc to keep .dt access\n",
    "        ts = pd.to_datetime(series, errors='coerce', utc=True)\n",
    "    if isinstance(ts, pd.Series):\n",
    "        tzinfo = getattr(ts.dt, 'tz', None)\n",
    "        if tzinfo is None:\n",
    "            return ts.dt.tz_localize(tz_name, ambiguous='NaT', nonexistent='shift_forward')\n",
    "        return ts.dt.tz_convert(tz_name)\n",
    "    if isinstance(ts, pd.DatetimeIndex):\n",
    "        if ts.tz is None:\n",
    "            return ts.tz_localize(tz_name, ambiguous='NaT', nonexistent='shift_forward')\n",
    "        return ts.tz_convert(tz_name)\n",
    "    ts_idx = pd.DatetimeIndex(ts)\n",
    "    if ts_idx.tz is None:\n",
    "        return ts_idx.tz_localize(tz_name, ambiguous='NaT', nonexistent='shift_forward')\n",
    "    return ts_idx.tz_convert(tz_name)\n",
    "\n",
    "# Respect provided local timestamps from the merged dataset\n",
    "local_ts = _ensure_tz(df['timestamp_local'], TZ_NAME)\n",
    "df['timestamp_local'] = local_ts\n",
    "df['SA'] = _ensure_tz(df['SA'], TZ_NAME)\n",
    "df['SU'] = _ensure_tz(df['SU'], TZ_NAME)\n",
    "\n",
    "# Normalize day_night to booleans (True = day, False = night)\n",
    "if df['day_night'].dtype != bool:\n",
    "    df['day_night'] = (\n",
    "        df['day_night']\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .map({'true': True, 'false': False, '1': True, '0': False})\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a46f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing class: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind_speed_ms</th>\n",
       "      <th>cloud_cover_oktas</th>\n",
       "      <th>day_night</th>\n",
       "      <th>ausbreitungsklasse_base</th>\n",
       "      <th>ausbreitungsklasse</th>\n",
       "      <th>ausbreitungsklasse_no_cloud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wind_speed_ms  cloud_cover_oktas  day_night ausbreitungsklasse_base  \\\n",
       "0            1.5                5.0      False                       I   \n",
       "1            1.6                NaN      False                    None   \n",
       "2            2.0                NaN      False                    None   \n",
       "3            1.7                NaN      False                    None   \n",
       "4            1.9                NaN      False                    None   \n",
       "\n",
       "  ausbreitungsklasse ausbreitungsklasse_no_cloud  \n",
       "0                  I                           I  \n",
       "1                  I                           I  \n",
       "2                  I                           I  \n",
       "3                  I                           I  \n",
       "4                  I                           I  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bin wind speed and cloud cover according to the table\n",
    "invalid_wind = (df['wind_speed_ms'] == -999) | (df['wind_dir_deg'] == -999)\n",
    "wind_speed_clean = df['wind_speed_ms'].where(~invalid_wind)\n",
    "\n",
    "wind_bins = [-np.inf, 1.2, 2.3, 3.3, 4.3, np.inf]\n",
    "wind_labels = ['<=1.2', '1.3-2.3', '2.4-3.3', '3.4-4.3', '>=4.4']\n",
    "wind_bin = pd.cut(wind_speed_clean, bins=wind_bins, labels=wind_labels)\n",
    "\n",
    "day_cloud_bin = pd.cut(\n",
    "    df['cloud_cover_oktas'], bins=[-np.inf, 2, 5, 8], labels=['0-2', '3-5', '6-8']\n",
    ")\n",
    "night_cloud_bin = pd.cut(\n",
    "    df['cloud_cover_oktas'], bins=[-np.inf, 6, 8], labels=['0-6', '7-8']\n",
    ")\n",
    "\n",
    "mapping_day = {\n",
    "    ('<=1.2', '0-2'): 'IV',\n",
    "    ('<=1.2', '3-5'): 'IV',\n",
    "    ('<=1.2', '6-8'): 'IV',\n",
    "    ('1.3-2.3', '0-2'): 'IV',\n",
    "    ('1.3-2.3', '3-5'): 'IV',\n",
    "    ('1.3-2.3', '6-8'): 'III/2',\n",
    "    ('2.4-3.3', '0-2'): 'IV',\n",
    "    ('2.4-3.3', '3-5'): 'IV',\n",
    "    ('2.4-3.3', '6-8'): 'III/2',\n",
    "    ('3.4-4.3', '0-2'): 'IV',\n",
    "    ('3.4-4.3', '3-5'): 'III/2',\n",
    "    ('3.4-4.3', '6-8'): 'III/2',\n",
    "    ('>=4.4', '0-2'): 'III/2',\n",
    "    ('>=4.4', '3-5'): 'III/1',\n",
    "    ('>=4.4', '6-8'): 'III/1',\n",
    "}\n",
    "\n",
    "mapping_night = {\n",
    "    ('<=1.2', '0-6'): 'I',\n",
    "    ('<=1.2', '7-8'): 'II',\n",
    "    ('1.3-2.3', '0-6'): 'I',\n",
    "    ('1.3-2.3', '7-8'): 'II',\n",
    "    ('2.4-3.3', '0-6'): 'II',\n",
    "    ('2.4-3.3', '7-8'): 'III/1',\n",
    "    ('3.4-4.3', '0-6'): 'III/1',\n",
    "    ('3.4-4.3', '7-8'): 'III/1',\n",
    "    ('>=4.4', '0-6'): 'III/1',\n",
    "    ('>=4.4', '7-8'): 'III/1',\n",
    "}\n",
    "\n",
    "df['klasse_kt'] = [mapping_day.get(k) for k in zip(wind_bin.astype(object), day_cloud_bin.astype(object))]\n",
    "df['klasse_kn'] = [mapping_night.get(k) for k in zip(wind_bin.astype(object), night_cloud_bin.astype(object))]\n",
    "df['ausbreitungsklasse_base'] = np.where(df['day_night'] == True, df['klasse_kt'], df['klasse_kn'])\n",
    "\n",
    "# Time windows around sunrise (SA) and sunset (SU)\n",
    "ts_utc = df['timestamp_local']\n",
    "sa_utc = df['SA']\n",
    "su_utc = df['SU']\n",
    "delta_sa = pd.TimedeltaIndex(ts_utc - sa_utc).total_seconds() / 3600\n",
    "delta_su = pd.TimedeltaIndex(ts_utc - su_utc).total_seconds() / 3600\n",
    "\n",
    "window = pd.Series(index=df.index, dtype='object')\n",
    "window.loc[(delta_sa >= 0) & (delta_sa < 1)] = 'SA+1..SA+2'\n",
    "window.loc[(delta_sa >= 1) & (delta_sa < 2)] = 'SA+1..SA+2'\n",
    "window.loc[(delta_sa >= 2) & (delta_sa < 3)] = 'SA+2..SA+3'\n",
    "window.loc[(delta_su >= -2) & (delta_su < -1)] = 'SU-2..SU-1'\n",
    "window.loc[(delta_su >= -1) & (delta_su < 0)] = 'SU-1..SU'\n",
    "window.loc[(delta_su >= 0) & (delta_su < 1)] = 'SU..SU+1'\n",
    "\n",
    "transition_map = {\n",
    "    ('I', 'IV', 'SA+1..SA+2'): ('I', 'II', 'a'),\n",
    "    ('I', 'IV', 'SA+2..SA+3'): ('II', None, None),\n",
    "    ('I', 'IV', 'SU-2..SU-1'): ('II', None, None),\n",
    "    ('I', 'IV', 'SU-1..SU'): ('II', 'I', 'b'),\n",
    "    ('I', 'IV', 'SU..SU+1'): ('I', 'II', 'a'),\n",
    "\n",
    "    ('I', 'III/2', 'SA+1..SA+2'): ('II', None, None),\n",
    "    ('I', 'III/2', 'SA+2..SA+3'): ('II', None, None),\n",
    "    ('I', 'III/2', 'SU-2..SU-1'): ('III/1', None, None),\n",
    "    ('I', 'III/2', 'SU-1..SU'): ('III/1', None, None),\n",
    "    ('I', 'III/2', 'SU..SU+1'): ('I', 'II', 'a'),\n",
    "\n",
    "    ('II', 'IV', 'SA+1..SA+2'): ('II', None, None),\n",
    "    ('II', 'IV', 'SA+2..SA+3'): ('III/1', None, None),\n",
    "    ('II', 'IV', 'SU-2..SU-1'): ('III/1', None, None),\n",
    "    ('II', 'IV', 'SU-1..SU'): ('II', None, None),\n",
    "    ('II', 'IV', 'SU..SU+1'): ('II', None, None),\n",
    "\n",
    "    ('II', 'III/2', 'SA+1..SA+2'): ('III/1', None, None),\n",
    "    ('II', 'III/2', 'SA+2..SA+3'): ('III/1', None, None),\n",
    "    ('II', 'III/2', 'SU-2..SU-1'): ('III/1', None, None),\n",
    "    ('II', 'III/2', 'SU-1..SU'): ('III/1', None, None),\n",
    "    ('II', 'III/2', 'SU..SU+1'): ('II', None, None),\n",
    "\n",
    "    ('III/1', 'IV', 'SA+1..SA+2'): ('III/1', None, None),\n",
    "    ('III/1', 'IV', 'SA+2..SA+3'): ('III/2', None, None),\n",
    "    ('III/1', 'IV', 'SU-2..SU-1'): ('III/2', None, None),\n",
    "    ('III/1', 'IV', 'SU-1..SU'): ('III/1', None, None),\n",
    "    ('III/1', 'IV', 'SU..SU+1'): ('III/1', None, None),\n",
    "\n",
    "    ('III/1', 'III/2', 'SA+1..SA+2'): ('III/1', None, None),\n",
    "    ('III/1', 'III/2', 'SA+2..SA+3'): ('III/1', None, None),\n",
    "    ('III/1', 'III/2', 'SU-2..SU-1'): ('III/2', None, None),\n",
    "    ('III/1', 'III/2', 'SU-1..SU'): ('III/2', None, None),\n",
    "    ('III/1', 'III/2', 'SU..SU+1'): ('III/1', None, None),\n",
    "\n",
    "    ('III/1', 'III/1', 'SA+1..SA+2'): ('III/1', None, None),\n",
    "    ('III/1', 'III/1', 'SA+2..SA+3'): ('III/1', None, None),\n",
    "    ('III/1', 'III/1', 'SU-2..SU-1'): ('III/1', None, None),\n",
    "    ('III/1', 'III/1', 'SU-1..SU'): ('III/1', None, None),\n",
    "    ('III/1', 'III/1', 'SU..SU+1'): ('III/1', None, None),\n",
    "}\n",
    "\n",
    "\n",
    "def _resolve_transition(kn, kt, win, base, month, wind, cloud):\n",
    "    val = transition_map.get((kn, kt, win))\n",
    "    if val is None:\n",
    "        return base\n",
    "    default, alt, rule = val\n",
    "    if alt and rule == 'a':\n",
    "        if (3 <= month <= 11) and (wind >= 1.3):\n",
    "            return alt\n",
    "    if alt and rule == 'b':\n",
    "        if (month in (1, 2, 12)) and (wind < 1.3) and (cloud <= 6):\n",
    "            return alt\n",
    "    return default\n",
    "\n",
    "\n",
    "months = pd.DatetimeIndex(df['timestamp_local']).month\n",
    "wind_for_logic = wind_speed_clean\n",
    "\n",
    "_df_wind = wind_for_logic\n",
    "_df_cloud = df['cloud_cover_oktas']\n",
    "_df_window = window\n",
    "_df_kn = df['klasse_kn']\n",
    "_df_kt = df['klasse_kt']\n",
    "_df_base = df['ausbreitungsklasse_base']\n",
    "df['ausbreitungsklasse'] = [\n",
    "    _resolve_transition(kn, kt, win, base, m, w, c)\n",
    "    for kn, kt, win, base, m, w, c in zip(\n",
    "        _df_kn,\n",
    "        _df_kt,\n",
    "        _df_window,\n",
    "        _df_base,\n",
    "        months,\n",
    "        _df_wind,\n",
    "        _df_cloud,\n",
    "    )\n",
    "]\n",
    "\n",
    "# Fallback for missing cloud_cover_oktas (use Table 4)\n",
    "cloud_missing = df['cloud_cover_oktas'].isna()\n",
    "wind_bins_nc = [-np.inf, 2.3, 3.3, np.inf]\n",
    "wind_labels_nc = ['<=2.3', '2.4-3.3', '>=3.4']\n",
    "wind_bin_nc = pd.cut(wind_for_logic, bins=wind_bins_nc, labels=wind_labels_nc)\n",
    "\n",
    "window_nc = pd.Series(index=df.index, dtype='object')\n",
    "window_nc.loc[(delta_sa < 1) | (delta_su >= 0)] = 'SU..SA+1'\n",
    "window_nc.loc[(delta_sa >= 1) & (delta_sa < 3)] = 'SA+1..SA+3'\n",
    "window_nc.loc[(delta_sa >= 3) & (delta_su <= -2)] = 'SA+3..SU-2'\n",
    "window_nc.loc[(delta_su > -2) & (delta_su < 0)] = 'SU-2..SU'\n",
    "\n",
    "mapping_nc = {\n",
    "    ('<=2.3', 'SU..SA+1'): 'I',\n",
    "    ('<=2.3', 'SA+1..SA+3'): 'II',\n",
    "    ('<=2.3', 'SA+3..SU-2'): 'III/2',\n",
    "    ('<=2.3', 'SU-2..SU'): 'III/1',\n",
    "    ('2.4-3.3', 'SU..SA+1'): 'II',\n",
    "    ('2.4-3.3', 'SA+1..SA+3'): 'III/1',\n",
    "    ('2.4-3.3', 'SA+3..SU-2'): 'III/2',\n",
    "    ('2.4-3.3', 'SU-2..SU'): 'III/1',\n",
    "    ('>=3.4', 'SU..SA+1'): 'III/1',\n",
    "    ('>=3.4', 'SA+1..SA+3'): 'III/1',\n",
    "    ('>=3.4', 'SA+3..SU-2'): 'III/1',\n",
    "    ('>=3.4', 'SU-2..SU'): 'III/1',\n",
    "}\n",
    "\n",
    "df['ausbreitungsklasse_no_cloud'] = [\n",
    "    mapping_nc.get(k) for k in zip(wind_bin_nc.astype(object), window_nc)\n",
    "]\n",
    "df['ausbreitungsklasse'] = np.where(\n",
    "    cloud_missing, df['ausbreitungsklasse_no_cloud'], df['ausbreitungsklasse']\n",
    ")\n",
    "\n",
    "# Summer uplift (VDI) rules\n",
    "class_order = ['I', 'II', 'III/1', 'III/2', 'IV', 'V']\n",
    "_next_class = {c: class_order[min(i + 1, len(class_order) - 1)] for i, c in enumerate(class_order)}\n",
    "\n",
    "def _upgrade(series, mask):\n",
    "    mapped = series.map(_next_class).fillna(series)\n",
    "    return pd.Series(np.where(mask, mapped, series), index=series.index)\n",
    "\n",
    "hours_local = pd.DatetimeIndex(df['timestamp_local']).hour\n",
    "summer = months.isin([6, 7, 8])\n",
    "\n",
    "mask_summer1 = summer & (hours_local >= 10) & (hours_local <= 16) & (\n",
    "    (df['cloud_cover_oktas'] <= 6) |\n",
    "    ((df['cloud_cover_oktas'] == 7) & (wind_for_logic < 2.4))\n",
    ")\n",
    "mask_summer2 = summer & (hours_local >= 12) & (hours_local <= 15) & (df['cloud_cover_oktas'] <= 5)\n",
    "mask_may_sep = months.isin([5, 9]) & (hours_local >= 11) & (hours_local <= 15) & (df['cloud_cover_oktas'] <= 6)\n",
    "\n",
    "df['ausbreitungsklasse'] = _upgrade(df['ausbreitungsklasse'], mask_summer1)\n",
    "df['ausbreitungsklasse'] = _upgrade(df['ausbreitungsklasse'], mask_summer2)\n",
    "df['ausbreitungsklasse'] = _upgrade(df['ausbreitungsklasse'], mask_may_sep)\n",
    "\n",
    "# Winter rule after transitions: replace class IV with III/2 in Dec, Jan, Feb\n",
    "winter_mask = months.isin([12, 1, 2])\n",
    "df.loc[winter_mask & (df['ausbreitungsklasse'] == 'IV'), 'ausbreitungsklasse'] = 'III/2'\n",
    "\n",
    "# Invalidate class when wind measurements are flagged as -999\n",
    "null_class = invalid_wind\n",
    "df.loc[null_class, 'ausbreitungsklasse'] = np.nan\n",
    "\n",
    "missing = df['ausbreitungsklasse'].isna().sum()\n",
    "print('missing class:', missing)\n",
    "df[['wind_speed_ms', 'cloud_cover_oktas', 'day_night', 'ausbreitungsklasse_base', 'ausbreitungsklasse', 'ausbreitungsklasse_no_cloud']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6fd949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U:\\Abt02\\Ref23\\Daten\\LQ-Modellierung\\06_Modellierung\\04_WINMiskam\\02_Meteorologie\\data\\processed\\merged_wind_cloud_2009_day_night_ausbreitung.csv\n",
      "U:\\Abt02\\Ref23\\Daten\\LQ-Modellierung\\06_Modellierung\\04_WINMiskam\\02_Meteorologie\\data\\processed\\akterm_2009_muenchen_stadt.akt\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(OUT_PATH, index=False)\n",
    "print(OUT_PATH)\n",
    "\n",
    "akterm_out = BASE_DIR / 'data' / 'processed' / f'akterm_{YEAR}_muenchen_stadt.akt'\n",
    "\n",
    "# Build AKTERM-style export in UTC (no header row for columns)\n",
    "ts_local = pd.to_datetime(df['timestamp_local'], errors='coerce')\n",
    "ts_idx = pd.DatetimeIndex(ts_local)\n",
    "if ts_idx.tz is None:\n",
    "    ts_idx = ts_idx.tz_localize(TZ_NAME)\n",
    "ts_utc = ts_idx.tz_convert('UTC')\n",
    "ts_out = pd.DatetimeIndex(ts_utc).tz_localize(None)\n",
    "\n",
    "# Keep only the target UTC year\n",
    "mask_year = (ts_out >= pd.Timestamp(f'{YEAR}-01-01 00:00:00')) & (ts_out < pd.Timestamp(f'{YEAR + 1}-01-01 00:00:00'))\n",
    "ts_out = ts_out[mask_year]\n",
    "df_masked = df.loc[mask_year].reset_index(drop=True)\n",
    "\n",
    "lines = []\n",
    "kennzahl_map = {\n",
    "    'I': '1',\n",
    "    'II': '2',\n",
    "    'III/1': '3',\n",
    "    'III/2': '4',\n",
    "    'IV': '5',\n",
    "    'V': '6',\n",
    "}\n",
    "for ts, sid, wdir, ws, ak in zip(ts_out, df_masked['STATIONS_ID'], df_masked['wind_dir_deg'], df_masked['wind_speed_ms'], df_masked['ausbreitungsklasse']):\n",
    "    sid_str = '' if pd.isna(sid) else f\"{int(sid):05d}\"\n",
    "    wdir_str = '' if pd.isna(wdir) else f\"{int(round(wdir))}\"\n",
    "    ws_str = '' if pd.isna(ws) else f\"{int(round(ws * 10))}\"\n",
    "    ak_str = '' if pd.isna(ak) else ak\n",
    "    if pd.isna(ak):\n",
    "        main_ak = ''\n",
    "        fehlwert = '-999'\n",
    "    else:\n",
    "        main_ak = kennzahl_map.get(str(ak), '')\n",
    "        fehlwert = ''\n",
    "\n",
    "    if pd.isna(ts):\n",
    "        year = month = day = hour = minute = ''\n",
    "    else:\n",
    "        year = f\"{ts.year:04d}\"\n",
    "        month = f\"{ts.month:02d}\"\n",
    "        day = f\"{ts.day:02d}\"\n",
    "        hour = f\"{ts.hour:02d}\"\n",
    "        minute = f\"{ts.minute:02d}\"\n",
    "\n",
    "    lines.append(\n",
    "        f\"AK {sid_str} {year} {month} {day} {hour} {minute} {wdir_str} {ws_str} {ak_str} {main_ak} {fehlwert}\"\n",
    "    )\n",
    "\n",
    "header_lines = [\n",
    "    '* AKTERM-Zeitreihe, Bayerisches Landesamt fuer Umwelt (LfU)',\n",
    "    '* Station Muenchen-Stadt mit Bedeckung Muenchen-Stadt',\n",
    "    f'* Zeitraum 01.01.{YEAR} - 31.12.{YEAR} (UTC).'\n",
    "]\n",
    "with akterm_out.open('w', encoding='utf-8') as f:\n",
    "    for line in header_lines:\n",
    "        f.write(line + '\\n')\n",
    "    for line in lines:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(akterm_out)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (meteorologie-env)",
   "language": "python",
   "name": "meteorologie-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
